easy_c 1.0

library Easy_C
library CV
library Math
library Map
library FEC

# A tag consists of a 12 x 12 matrix of bits that encodes 64-bits of
# information in an 8 x 8 data matrix.  The outermost square of the matrix
# is set to zeros (white squares) and the next level in is 1's
# (black squares).  When viewed in an upright form printed on paper
# it looks as follows (-- = zero, XX = one, ## = bit number):
#
# -- -- -- -- -- -- -- -- -- -- -- --
# -- XX XX XX XX XX XX XX XX XX XX -- 
# -- XX 56 57 58 59 60 61 62 63 XX --
# -- XX 48 49 50 51 52 53 54 55 XX --
# -- XX 40 41 42 43 44 45 45 47 XX --
# -- XX 32 33 34 35 36 37 38 39 XX --
# -- XX 24 25 26 27 28 29 30 31 XX --
# -- XX 16 17 18 19 20 21 22 23 XX --
# -- XX 08 09 10 11 12 13 14 15 XX --
# -- XX 00 01 02 03 04 05 06 07 XX --
# -- XX XX XX XX XX XX XX XX XX XX -- 
# -- -- -- -- -- -- -- -- -- -- -- --
#
# To make things a little complicated, Scalable Vector Graphics
# has its origin up in the upper left of the page.

# When it comes to performing the image analysis of a picture to
# compute robot location and bearing there are three coordinate systems
# to consider -- the floor, camera, and robot coordinate systems:
#
#     -	The floor coordinate system is a right handed cartesian
#	coordinate system where one point on the floor is the
#	origin.  The X and Y axes are separated by a 90 degree
#	angle and X axis can be oriented to aligned with either a
#	building feature or an east-west line of latitude or
#	whatever the user chooses.  Conceptually, the floor is
#	viewed from the top looking down.  As long as all length
#	measurements are performed using the same units, the
#	choice of length unit does not actually matter (e.g.
#	meter, centimeter, millimeter, inch, foot, etc.)
#
#     -	The image coordinate system is another right handed cartesian
#	coordinate system that is used to locate the individual
#	pixels in the image.  The image is one of the common image
#	format sizes (320 x 240, 640 x 480, etc.)  For this system,
#	the origin is selected to be the lower left pixel of the
#	image.  For 640 x 480 image, the lower left coordinate is
#	(0, 0) and the upper right pixel coordinate is (639, 479).
#	While computer imaging systems typically use a left-handed
#	coordinate system where the origin is in the upper left,
#	we will apply a transformation that causes the origin to
#	be placed in the lower left.  All distances are measured
#	in units of pixels.
#
#     -	The robot coordinate system is another right handed cartesian
#	coordinate system where the origin is located in the center
#	between the two drive wheels.  The X axis of the robot
#	coordinate system goes through the front of the robot.
#
# Conceptually there a bunch of square fiducial tags (hereafter called
# just tags) scattered on the floor.  For each tag, we record the following
# information in an ordered quintuple:
#
#    (tid, tx, ty, tb, te)
#
# where:
#
#    tid	is the tag identifier (a number between 0 and 2^16-1),
#    tx		is the x coordinate of the tag center (floor coord.),
#    ty		is the y coordinate of the tag center (floor coord.),
#    tb		is the angle (bearing) of the bottom tag edge and the
#		floor X axis (floor coord.), and
#    te		is the length of a tag edge (all 4 sides of a square
#		have the same edge length) (floor coord.)
#
# Conceptually, the camera is going to be placed a fixed distance
# above the floor and take an image of rectangular area of the floor.
# If image contains one or more tags, the image processing algorithm
# computes the following ordered triple:
#
#	(cx, cy, cb)
#
# where:
#
#    cx		is the X coordinate of the image rectangle center
#		(floor coord.),
#    cy		is the Y coordinate of the image rectangle center
#		(floor coord.), and
#    cb		is the angle (bearing) of the rectangle bottom edge with
#		respect to the floor X axis (floor coord.)
#
# Conceptually, the floor is printed out on a large sheet of paper
# with all of the tags present.  The camera image is printed out on
# a piece of translucent material (e.g. acetate) with the same dimensions
# as the floor sheet.  This translucent image is placed on the floor
# sheet and moved around until the image tag(s) align with the
# corresponding tag(s) on the floor sheet.  The translucent image
# center is now sitting directly on top of (cx, cy) on the floor sheet.
# The amount of "twist" on the image is cb.  Hopefully, this mental
# image of what we are trying to accomplish will help as you wade
# through the math below.
#
# When an image contains a tag, what we are doing is computing
# the function F below:
#
#    (cx, cy, cb) = F( (tid, tx, ty, ta, te), (c0, c1, c2, c3) )
#
# where
#
#    (cx, cy, cb)		is camera location and orientation
#				result as defined before (floor coord.),
#    (tid, tx, ty, tb, te)	is the tag quintuple as defined before
#				(floor coord.), and
#    (c0, c1, c2, c3)		is are the coordinates of the 4 tag
#				corners in the image.
#
# c0, c1, c2, and c3 are actually ordered pairs (c0x, c0y), (c1x, c1y),
# (c2x, c2y) and (c3x, c3y).  c0 is next to the least significant bit
# of the tag id, c1 is next to the most significant bit of the tag id,
# c2 is above c1, and c3 is above c0.  The 4 corners go in a clockwise
# direction around the tag (when viewed from above, of course.)  The tag
# looks as follows in ASCII art:
#
#      +Y
#       ^
#       |
#       |  c2                         c3
#       |     ** ** ** ** ** ** ** **
#       |     ** ** ** ** ** ** ** **
#       |     ** ** ** ** ** ** ** **
#       |     ** ** ** ** ** ** ** **
#       |     ** ** ** ** ** ** ** **
#       |     ** ** ** ** ** ** ** **
#       |     15 14 13 12 11 10  9  8
#       |      7  6  5  4  3  2  1  0
#       |  c1                         c0
#       |
#       +--------------------------------> +X
#
# where 0 through 15 are the bit numbers of the tag id.  The
# ASCII art above, does not have any tag twist; it just shows
# where the corners are located with respect to tag bits.
#
# Using (c0, c1, c2, c3), we compute the following:
#
#    (tagctrx, tagctry)		is the camera center (image coord.),
#    tagdiag			is the camera diagonal (image coord.)
#    tagtwist			is the angle of the lower tag edge
#				(image coord.)
#
# These values are computed as follows:
#
#   tagctrx = (c0x + c1x + c2x + c3x) / 4	# The average of the X's
#   tagctry = (c0y + c1y + c2y + c3y) / 4	# The average of the Y's
#
#   tagdiag1 = sqrt( (c0x-c2x)^2 + (c0y-c2y)^2) )	# First diagonal
#   tagdiag2 = sqrt( (c1x-c3x)^2 + (c1y-c3y)^2) )	# Second diagonal
#   tagdiag = (tagdiag1 + tagdiag2) / 2		# Average of both diagonals
#   tagtwist = arctangent2(c0y - c1y, c0x - c1y) # Bottom tag edge angle
#
# The image center is defined as:
#
#	(camctrx, camctry)
#
# where
#
#    camctrx	is the image center X coordinate (image coord.)
#    camctry	is the image center Y coordinate (image coord.)
#
# for an image that is 640 x 480, the image center is (320, 240).
#
# Using the image center the following values are computed:
#
#    camdist		is the distance from the tag center to camera
#			center (image coord.), and
#    camctrangle	is the angle from the tag center to the camera
#			center (image coord.)
#
# These two values are computed as:
#
#    camdist = sqrt( (camctrx - tagctrx)^2 + (camctry - tagctry)^2) )
#    camctrangle = arctangent2( camctry - tagctry, camctrx - tagctry)
#
# Now camdist needs to be converted from a distance in pixels into
# a distance on the floor.  This is done using tagdiag and te (the
# tag edge length.
#
#    flrcamdist = camdist * (te * sqrt(2) / tagdiag )
#
# Need to compute to angles that are measured relative to the
# floor X axis:
#
#    cb		is the direction that the camera X axis points
#		relative to the floor X Axis.
#    ca		is the direction to the image center relative
#		to the floor X Axis
#
# cb and ca are computed as:
#
#    cb = tb - tagtwist
#
#    ca = cb + camctrangle
#
# Now cx, and cy are computed as follows:
#
#    cx = tx + flrcamdist * cos(ca)
#    cy = ty = flrcamdist * sin(ca)
#
# Thus, the final result of (cx, cy, cb) has been determined.
#
# Once we know the camera location and orientation, (ca, cy, cb),
# we need to compute the ordered triple:
#
#    (rx, ry, rb)
#
# where
#
#    rx		is the X coordinate of the robot center (floor coord.),
#    ry		is the Y coordinate of the robot center (floor coord.),
#    rb		is the bearing angle of the robot X axis (floor coord.)
#
# These values are computed as a function:
#
#    (rx, ry, rb) = F( (cx, cy, cb) )
#
# There are two constants need to do this computation:
#
#    robdist		is the distance from the camera center to the robot
#			center, and
#    robcamangle	is the angle from the angle from camera X axis to the
#			robot X axis.
#
# Both robdist and robangle are constants that can be directly measured
# from the camera placement relative to the robot origin.
#
# Now (rx, ry, rb) can be computed as follows:
#
#    rb = cb + robcamangle
#    rx = robdist * cos(rb)
#    ry = robdist * sin(rb)
#
# That covers the image processing portion of the algorithm.
#
# The robot dead reckoning system keeps track of the robot position
# using wheel encoders.  These values are represented in the ordered
# triple:
#
#    (ex, ey, eb)
#
# where
#
#    ex		is the robot X coordinate (floor coord.),
#    ey		is the robot Y coordinate (floor coord.), and
#    eb		is the robot X axis bearing (floor coord.)
#
# (rx, ry, rb and (ex, ey, eb) are supposed to be the same.  Over
# time, small errors will accumulate in the computation of (ex, ey, eb).
# (rx, ry, rb) can be used to reset (ex, ey, eb).
#
# That pretty much summarizes what the basic algorithm does.
#
# What remains is to do the transformations that place the tags
# on the ceiling.  There are three transformations.
#
#    tags lift		The tags are lifted straight up from the floor
#			to the ceiling.  The person looking on down
#			from above would see no changes in tag position
#			or orientation (ignoring parallax issues.)
#
#    camera flip	The camera is rotated 180 degrees around the
#			camera X axis.  The causes the Y axis to change
#			its sign.
#
#    image framing	For historical reasons, the camera image API
#			provides the camera image with the image origin
#			in upper left hand corner, whereas the all of
#			the math above assumes that image origin is
#			in the lower left corner.  It turns out this
#			is just changes the Y axis sign again.
#
# The bottom line is that the "camera flip" and the "image framing"
# transformation cancel one another out.  Thus, the there is no
# work needed to tweak the equations above.

# This is old.  The text above should be much easier to understand.

# Now it is time to talk about coordinate systems.  There are a bunch
# of them and they make things confusing.
#
# A) OpenCV Coordinate system:
#        Like most imaging software, OpenCV places the origin in the
#	 upper left corner with the Y axis going down:
#
#	     O--------------> X+
#	     | iiiiiiiiiiiii
#            | iiiiiiiiiiiii
#            v
#            Y+
#
#        The "iiiiiiiiii" shows where the image lives in the
#        coordinate system.  This coordinate system is left hand
#        rule.
#
# B) Image cartesian coordinate system:
#	 This is an intermediate transform where the Y axis is flipped
#	 into a upward direction.:
#
#            Y+
#            ^
#            |
#            O--------------> X+
#            | iiiiiiiiiiii
#            | iiiiiiiiiiii
#            v
#            Y-
#
#        In this coordinate system Y=>-Y.  The nice thing is that
#        angles computed in this coordinate system are visually the
#        same as what is used in the rest of mathematcs.  Thus the
#        vector from (x1,y1) to (x2,y2) = atan2(y2-y1,x2-x1) is
#        can be verified by looking at the image on the screen to
#        to see if it is pointing the right direction.  This coordinate
#        system is right hand rule.
#
# C) Tag coordinate system:
#        In this coordinate system the tag (i.e. fiducial) center
#        is the origin with the X axis going straight out the "right"
#        side of the tag:
#
#                Y+
#                ^
#                |
#            +---+---+
#            |   |   |
#            |   O---+----> X+
#            |       |
#            +-------+
#
#        Again, this coordinate system can be visually inspected by
#        looking at the image.
#
# D) Map coordinate system:
#        The final map coordinate system is an absolute coordinate
#        system where one of the tags is selected as the origin and
#        the position of all other tags are measured relative from
#        this origin:
#
#            Y+           +-------+            +-------+
#            ^            |       |            |       |
#            |            |       |            |       |
#            |            |       |            |       |
#            |            +-------+            +-------+
#            |
#        +---+---+                                             +------+
#        |   |   |                                             |      |
#        |   O---+------------>X+                              |      |
#        |       |                                             |      |
#        +-------+                                             +------+
#
#        While the image above shows all the tags with the same orientation,
#        each tag can actually be twisted by an amount.  Switch from the
#        an image of the ceiling down to the map coordinate system which
#        can be visualized as being on the floor, involves flipping either
#        X axis or the Y axis.  I choose to flip the X axis.

define Bit_Field			# Field of bits
    record
	size Unsigned			# Maximum number of bits
	bits String			# Bit vector

define Extractor
    record
	blur Logical			# {true}=>blur prior to edge extract
	bit_field Bit_Field		# Bit field for tag bits
	blue CV_Scalar			# Color blue
	cyan CV_Scalar			# Color blue
	camera CV_Matrix		# Camera matrix
	camera_position CV_Matrix	# Camera position matrix
	ccitt Array[Unsigned]		# CR16-CCITT lookup table
	#corners Array[CV_Point2D32F]	# 4 corners of tag
	corners_vector CV_Point2D32F_Vector # 4 corners of tag
	constants Constants		# (contains camera_dx/dy)
	debug_image CV_Image		# Debugging image
	edge_image CV_Image		# Edge extracted version of image
	fec FEC				# Forward error corrector
	gray_image CV_Image		# Gray scale of image
	green CV_Scalar			# Color green
	height Integer			# Image height
	previous_bearing Double
	previous_x Double
	previous_y Double
	last_bearing Double		# Last bearing (radians)
	last_distance Double		# Distance from tag to image center
	last_tag Tag			# Last Tag
	last_x Double			# Last X location
	last_y Double			# Last Y location
	map Map				# Map in
	mapping Array[Unsigned]		# Temporary mapping
	mappings Array[Array[Unsigned]]	# The 4 tag mapping orientations
	mapping_names Array[String]	# Mapping names
	one CV_Scalar			# (1.0, 0.0, 0.0, 0.0)
	origin CV_Point			# (0,0) {CV_Point} object
	pi Double			# A constant
	point1 CV_Matrix		# {point1} 
	point2 CV_Matrix		# {point2} 
	purple CV_Scalar		# Color purple
	#rotation_matrix CV_Matrix	# Temporary rotation matrix
	#rotation_vector CV_Matrix	# Rotation vector
	distortion_coefficients CV_Matrix # Camera lens distortion coefficents
	red CV_Scalar			# Color red
	references Array[CV_Point2D32F]	# Reference points around {corners}
	sample_points Array[CV_Point2D32F] # Sample points for tag
	size CV_Size			# {CV_Size} contains {width} & {height}
	size_5x5 CV_Size		# {CV_Size} set to 5x5
	size_m1xm1 CV_Size		# {CV_Size} set to -1x-1
	storage CV_Memory_Storage	# Memory Storage object
	tag_bits Array[Logical]		# 64 tag bit values
	tag_bytes Array[Unsigned]	# Extracted tag bytes
	tag_points_2d CV_Matrix		# Tag corner points in 2D
	tag_points_3d CV_Matrix		# Tag corner points in 2D
	tags Array[Tag]			# Tags found in image
	temporary String		# Temporary {String}
	term_criteria CV_Term_Criteria	# Termination critera
	translation_vector CV_Matrix	# Translation vector
	visit_counter Unsigned		# Unique visit counter
	width Integer			# Image width

# {Array} routines:

routine show@Array[Element]
    takes array Array[Element]
    takes show [<=Element]
    returns_nothing

    size :@= array.size
    index :@= 0
    while index < size
	call show(array[index])
	index := index + 1


# {Extractor} routines:

routine create@Extractor
    returns Extractor

    # This routine will create and return a {Extractor} object.  It is
    # very important to call {size_set@Extractor} to get height and width
    # set before trying to use the returned {Extractor} object.

    # {corners_vector} holds the 4 tag corners:
    corners_vector :@= create@CV_Point2D32F_Vector(4)

    # Create {corners} which points to the four values of {corners_vector}:
    corners :@= new@Array[CV_Point2D32F]()
    index :@= 0
    while index < 4
	call append@(corners, corners_vector[index])
	index := index + 1

    # Create {references} which has the 8 sample locations:
    references :@= new@Array[CV_Point2D32F]()
    index := 0
    while index < 8
	call append@(references, create@CV_Point2D32F(0.0, 0.0))
	index := index + 1

    # Create {sample_points} to have 64 sample locations;
    sample_points :@= new@Array[CV_Point2D32F]()
    index := 0
    while index < 64
	call append@(sample_points, create@CV_Point2D32F(0.0, 0.0))
	index := index + 1

    # The mappings specify where to select bits:
    
    north_mapping :@= new@Array[Unsigned]()
    #                         corner1                      corner0
    call append8@(north_mapping,  0,  1,  2,  3,  4,  5,  6,  7)
    call append8@(north_mapping,  8,  9, 10, 11, 12, 13, 14, 15)
    call append8@(north_mapping, 16, 17, 18, 19, 20, 21, 22, 23)
    call append8@(north_mapping, 24, 25, 26, 27, 28, 29, 30, 31)
    call append8@(north_mapping, 32, 33, 34, 35, 36, 37, 38, 39)
    call append8@(north_mapping, 40, 41, 42, 43, 44, 45, 46, 47)
    call append8@(north_mapping, 48, 49, 50, 51, 52, 53, 54, 55)
    call append8@(north_mapping, 56, 57, 58, 59, 60, 61, 62, 63)
    #                         corner2                       corner3

    west_mapping :@= new@Array[Unsigned]()
    #                         corner1                      corner0
    call append8@(west_mapping,  7, 15, 23, 31, 39, 47, 55, 63)
    call append8@(west_mapping,  6, 14, 22, 30, 38, 46, 54, 62)
    call append8@(west_mapping,  5, 13, 21, 29, 37, 45, 53, 61)
    call append8@(west_mapping,  4, 12, 20, 28, 36, 44, 52, 60)
    call append8@(west_mapping,  3, 11, 19, 27, 35, 43, 51, 59)
    call append8@(west_mapping,  2, 10, 18, 26, 34, 42, 50, 58)
    call append8@(west_mapping,  1,  9, 17, 25, 33, 41, 49, 57)
    call append8@(west_mapping,  0,  8, 16, 24, 32, 40, 48, 56)
    #                         corner2                       corner3

    south_mapping :@= new@Array[Unsigned]()
    #			      corner1                       corner0
    call append8@(south_mapping, 63, 62, 61, 60, 59, 58, 57, 56)
    call append8@(south_mapping, 55, 54, 53, 52, 51, 50, 49, 48)
    call append8@(south_mapping, 47, 46, 45, 44, 43, 42, 41, 40)
    call append8@(south_mapping, 39, 38, 37, 36, 35, 34, 33, 32)
    call append8@(south_mapping, 31, 30, 29, 28, 27, 26, 25, 24)
    call append8@(south_mapping, 23, 22, 21, 20, 19, 18, 17, 16)
    call append8@(south_mapping, 15, 14, 13, 12, 11, 10,  9,  8)
    call append8@(south_mapping,  7,  6,  5,  4,  3,  2,  1,  0)
    #                         corner2                       corner3

    east_mapping :@= new@Array[Unsigned]()
    #			      corner1                       corner0
    call append8@(east_mapping, 56, 48, 40, 32, 24, 16,  8,  0)
    call append8@(east_mapping, 57, 49, 41, 33, 25, 17,  9,  1)
    call append8@(east_mapping, 58, 50, 42, 34, 26, 18, 10,  2)
    call append8@(east_mapping, 59, 51, 43, 35, 27, 19, 11,  3)
    call append8@(east_mapping, 60, 52, 44, 36, 28, 20, 12,  4)
    call append8@(east_mapping, 61, 53, 45, 37, 29, 21, 13,  5)
    call append8@(east_mapping, 62, 54, 46, 38, 30, 22, 14,  6)
    call append8@(east_mapping, 63, 55, 47, 39, 31, 23, 15,  7)
    #                         corner2                       corner3

    # Create the {mappings} table that has the 4 possible mapping tables
    # inside.  At the same time load up {mapping_names}:
    mappings :@= new@Array[Array[Unsigned]]()
    mapping_names :@= new@Array[String]()
    call append@(mappings, north_mapping)
    call append@(mapping_names, "North")
    call append@(mappings, east_mapping)
    call append@(mapping_names, "East")
    call append@(mappings, south_mapping)
    call append@(mapping_names, "South")
    call append@(mapping_names, "West")
    call append@(mappings, west_mapping)

    # This table is the CRC of each possible byte. It can be computed
    # using standard bit-at-a-time methods.  Alas, there are a whole
    # slew of different twists on the CRC16-CCITT algorithm depending
    # upon initial values (0 or 0xffff) and MSB vs. LSB, etc.
    # The ageed apon polynomial is X^16+X^12+X^5+X^1, which when
    # dropping the 17th bit, is 0x1021.  However, by doing the LSB
    # first, this reverses things to 0x8408, which shows up in the
    # table below at index 128.
    ccitt :@= new@Array[Unsigned]()
    call append8@(ccitt,
      0x0000, 0x1189, 0x2312, 0x329b, 0x4624, 0x57ad, 0x6536, 0x74bf)
    call append8@(ccitt,
      0x8c48, 0x9dc1, 0xaf5a, 0xbed3, 0xca6c, 0xdbe5, 0xe97e, 0xf8f7)
    call append8@(ccitt,
      0x1081, 0x0108, 0x3393, 0x221a, 0x56a5, 0x472c, 0x75b7, 0x643e)
    call append8@(ccitt,
      0x9cc9, 0x8d40, 0xbfdb, 0xae52, 0xdaed, 0xcb64, 0xf9ff, 0xe876)
    call append8@(ccitt,
      0x2102, 0x308b, 0x0210, 0x1399, 0x6726, 0x76af, 0x4434, 0x55bd)
    call append8@(ccitt,
      0xad4a, 0xbcc3, 0x8e58, 0x9fd1, 0xeb6e, 0xfae7, 0xc87c, 0xd9f5)
    call append8@(ccitt,
      0x3183, 0x200a, 0x1291, 0x0318, 0x77a7, 0x662e, 0x54b5, 0x453c)
    call append8@(ccitt,
      0xbdcb, 0xac42, 0x9ed9, 0x8f50, 0xfbef, 0xea66, 0xd8fd, 0xc974)
    call append8@(ccitt,
      0x4204, 0x538d, 0x6116, 0x709f, 0x0420, 0x15a9, 0x2732, 0x36bb)
    call append8@(ccitt,
      0xce4c, 0xdfc5, 0xed5e, 0xfcd7, 0x8868, 0x99e1, 0xab7a, 0xbaf3)
    call append8@(ccitt,
      0x5285, 0x430c, 0x7197, 0x601e, 0x14a1, 0x0528, 0x37b3, 0x263a)
    call append8@(ccitt,
      0xdecd, 0xcf44, 0xfddf, 0xec56, 0x98e9, 0x8960, 0xbbfb, 0xaa72)
    call append8@(ccitt,
      0x6306, 0x728f, 0x4014, 0x519d, 0x2522, 0x34ab, 0x0630, 0x17b9)
    call append8@(ccitt,
      0xef4e, 0xfec7, 0xcc5c, 0xddd5, 0xa96a, 0xb8e3, 0x8a78, 0x9bf1)
    call append8@(ccitt,
      0x7387, 0x620e, 0x5095, 0x411c, 0x35a3, 0x242a, 0x16b1, 0x0738)
    call append8@(ccitt,
      0xffcf, 0xee46, 0xdcdd, 0xcd54, 0xb9eb, 0xa862, 0x9af9, 0x8b70)
    call append8@(ccitt,
      0x8408, 0x9581, 0xa71a, 0xb693, 0xc22c, 0xd3a5, 0xe13e, 0xf0b7)
    call append8@(ccitt,
      0x0840, 0x19c9, 0x2b52, 0x3adb, 0x4e64, 0x5fed, 0x6d76, 0x7cff)
    call append8@(ccitt,
      0x9489, 0x8500, 0xb79b, 0xa612, 0xd2ad, 0xc324, 0xf1bf, 0xe036)
    call append8@(ccitt,
      0x18c1, 0x0948, 0x3bd3, 0x2a5a, 0x5ee5, 0x4f6c, 0x7df7, 0x6c7e)
    call append8@(ccitt,
      0xa50a, 0xb483, 0x8618, 0x9791, 0xe32e, 0xf2a7, 0xc03c, 0xd1b5)
    call append8@(ccitt,
      0x2942, 0x38cb, 0x0a50, 0x1bd9, 0x6f66, 0x7eef, 0x4c74, 0x5dfd)
    call append8@(ccitt,
      0xb58b, 0xa402, 0x9699, 0x8710, 0xf3af, 0xe226, 0xd0bd, 0xc134)
    call append8@(ccitt,
      0x39c3, 0x284a, 0x1ad1, 0x0b58, 0x7fe7, 0x6e6e, 0x5cf5, 0x4d7c)
    call append8@(ccitt,
      0xc60c, 0xd785, 0xe51e, 0xf497, 0x8028, 0x91a1, 0xa33a, 0xb2b3)
    call append8@(ccitt,
      0x4a44, 0x5bcd, 0x6956, 0x78df, 0x0c60, 0x1de9, 0x2f72, 0x3efb)
    call append8@(ccitt,
      0xd68d, 0xc704, 0xf59f, 0xe416, 0x90a9, 0x8120, 0xb3bb, 0xa232)
    call append8@(ccitt,
      0x5ac5, 0x4b4c, 0x79d7, 0x685e, 0x1ce1, 0x0d68, 0x3ff3, 0x2e7a)
    call append8@(ccitt,
      0xe70e, 0xf687, 0xc41c, 0xd595, 0xa12a, 0xb0a3, 0x8238, 0x93b1)
    call append8@(ccitt,
      0x6b46, 0x7acf, 0x4854, 0x59dd, 0x2d62, 0x3ceb, 0x0e70, 0x1ff9)
    call append8@(ccitt,
      0xf78f, 0xe606, 0xd49d, 0xc514, 0xb1ab, 0xa022, 0x92b9, 0x8330)
    call append8@(ccitt,
      0x7bc7, 0x6a4e, 0x58d5, 0x495c, 0x3de3, 0x2c6a, 0x1ef1, 0x0f78)

    term_criteria_type :@= term_criteria_iterations@CV | term_criteria_eps@CV
    term_criteria :@= create@CV_Term_Criteria(term_criteria_type, 5i, 0.2)

    #FIXME: Many of these are no longer used!!!
    camera :@= create_mat@CV(3i, 3i, f64c1@CV)
    distortion_coefficients :@= create_mat@CV(4i, 1i, f64c1@CV)
    rotation_matrix :@= create_mat@CV(3i, 3i, f64c1@CV)
    rotation_vector :@= create_mat@CV(1i, 3i, f64c1@CV)
    translation_vector :@= create_mat@CV(1i, 3i, f64c1@CV)
    camera_position :@= create_mat@CV(4i, 4i, f64c1@CV)
    tag_points_2d :@= create_mat@CV(4i, 2i, f64c1@CV)
    tag_points_3d :@= create_mat@CV(4i, 3i, f64c1@CV)

    #FIXME: Many of these values are no longer used!!!
    one :@= create@CV_Scalar(1.0, 0.0, 0.0, 0.0)
    call set_identity@CV(camera, one)
    call set_identity@CV(distortion_coefficients, one)
    call set_identity@CV(rotation_matrix, one)
    call set_identity@CV(rotation_vector, one)
    call set_identity@CV(translation_vector, one)
    call set_identity@CV(camera_position, one)
    call set_identity@CV(tag_points_2d, one)
    call set_identity@CV(tag_points_3d, one)

    #FIXME: Is this stuff being used anymore!!!
    #FIXME: Hack values into {camera}:
    call set_real_2d@CV(camera, 0i, 0i, 677.869)
    call set_real_2d@CV(camera, 1i, 1i, 564.028)
    call set_real_2d@CV(camera, 0i, 2i, 332.416)
    call set_real_2d@CV(camera, 1i, 2i, 282.044)
    call set_real_2d@CV(distortion_coefficients, 0i, 0i, 2.359)
    call set_real_2d@CV(distortion_coefficients, 1i, 0i, -4.532)
    call set_real_2d@CV(distortion_coefficients, 2i, 0i, -0.117)
    call set_real_2d@CV(distortion_coefficients, 3i, 0i, 0.303)

    # Create and load up {extractor}:
    extractor :@= new@Extractor()
    extractor.bit_field := create@Bit_Field(64) 
    extractor.blue := rgb@CV_Scalar(0.0, 0.0, 255.0)
    extractor.cyan := rgb@CV_Scalar(0.0, 255.0, 255.0)
    extractor.camera := camera
    extractor.camera_position := camera_position
    extractor.ccitt := ccitt
    extractor.constants := empty_create@Constants()
    extractor.corners_vector := corners_vector
    extractor.distortion_coefficients := distortion_coefficients
    extractor.edge_image := null@CV_Image
    extractor.fec := create@FEC(8, 4, 4)
    extractor.gray_image := null@CV_Image
    extractor.green := rgb@CV_Scalar(0.0, 255.0, 0.0)
    extractor.debug_image := null@CV_Image
    extractor.height := -1i
    extractor.previous_bearing := 0.0
    extractor.previous_x := 0.0
    extractor.previous_y := 0.0
    extractor.last_bearing := -12345678.0
    extractor.last_x := 0.0
    extractor.last_y := 0.0
    extractor.map := create@Map()
    extractor.mapping := new@Array[Unsigned]()
    extractor.mappings := mappings
    extractor.mapping_names := mapping_names
    extractor.point1 := create_mat@CV(1i, 3i, f64c1@CV)
    extractor.point2 := create_mat@CV(1i, 3i, f64c1@CV)
    extractor.one := one
    extractor.origin := create@CV_Point(0i, 0i)
    extractor.pi := 3.14159265358979323846
    extractor.purple := rgb@CV_Scalar(255.0, 0.0, 255.0)
    extractor.red := rgb@CV_Scalar(255.0, 0.0, 0.0)
    extractor.references := references
    extractor.sample_points := sample_points
    extractor.size := null@CV_Size
    extractor.size_5x5 := create@CV_Size(5i, 5i)
    extractor.size_m1xm1 := create@CV_Size(-1i, -1i)
    extractor.storage := create_mem_storage@CV(0i)
    extractor.tag_bits := new@Array[Logical]()
    extractor.tag_bytes := new@Array[Unsigned]()
    extractor.tag_points_2d := tag_points_2d
    extractor.tag_points_3d := tag_points_3d
    extractor.tags := new@Array[Tag]()
    extractor.translation_vector := translation_vector
    extractor.temporary := new@String()
    extractor.term_criteria := term_criteria
    extractor.visit_counter := 0
    extractor.width := -1i

    # Do a little error checking:
    call mapping_check@(extractor, north_mapping, "north")
    call mapping_check@(extractor, east_mapping, "east")
    call mapping_check@(extractor, west_mapping, "west")
    call mapping_check@(extractor, south_mapping, "south")

    return extractor


routine extract@Extractor
    takes extractor Extractor
    takes original_image CV_Image
    takes debug_index Unsigned
    takes indent Unsigned
    returns Array[Tag]

    # This routine will process {original_image} using {extractor}.
    # Debugging information capture using {debug_index}.

    trace :@= indent < 0xffff0000
    if trace
	call d@(form@("%p%=>extract@Extractor(*, *, %d%)\n\") %
	  f@(indent) / f@(debug_index))
    indent1 :@= indent + 1

    debug_image :@= extractor.debug_image
    edge_image :@= extractor.edge_image
    gray_image :@= extractor.gray_image
    storage :@= extractor.storage
    map :@= extractor.map
    map_changed :@= map.changed

    #buffer :@= new@Array[Unsigned]()
    #call append@(buffer, 0)
    #index :@= 0
    #while index < 4
    #	buffer[0] := index
    #	call d@(form@("[%d%]: %x%\n\") %
    #	  f@(index) / f@(crc@(extractor,buffer, 1)))
    #	index := index + 1

    # Show the initial gray image:
    
    # Clear memory storage:
    call clear_mem_storage@CV(storage)

    # Copy {original_image} to {gray_image} converting from color to gray
    # if necessary:
    channels :@= original_image.channels
    if channels = 3i
	# {original_image} is color; convert to gray:
	call cvt_color@CV(original_image, gray_image, rgb_to_gray@CV)
    else_if channels = 1i
	# {original_image} is gray; do a simple copy:
	call copy@CV(original_image, gray_image, null@CV_Image)

    # For debugging, show the original image:
    if debug_index = 1
	call cvt_color@CV(gray_image, debug_image, gray_to_rgb@CV)

    # Blur the image if requested:
    if extractor.blur
	call smooth@CV(gray_image, gray_image, gaussian@CV, 3i, 0i, 0.0, 0.0)

    # For debugging show the blurred image:
    if debug_index = 2
	call cvt_color@CV(gray_image, debug_image, gray_to_rgb@CV)

    # Perform edge detection:
    call adaptive_threshold@CV(gray_image, edge_image, 255.0,
      adaptive_thresh_gaussian_c@CV, thresh_binary@CV, 45i, 5.0)

    # For debugging, show the edge detected image:
    if debug_index = 3
	call cvt_color@CV(edge_image, debug_image, gray_to_rgb@CV)

    # Find the edge contours:
    origin :@= extractor.origin
    header_size :@= 128i
    contours :@= find_contours@CV(edge_image, storage,
      header_size, retr_list@CV, chain_approx_simple@CV, origin)
    if contours == null@CV_Sequence
	call d@("no contours found\n\")

    # For debugging show the edge contours:
    if debug_index = 4
	red :@= extractor.red
	call cvt_color@CV(gray_image, debug_image, gray_to_rgb@CV)
	call draw_contours@CV(debug_image,
	  contours, red, red, 2i, 2i, 8i, origin)

    # For the remaining debug steps, we use the original {gray_image}:
    if debug_index >= 5
	call cvt_color@CV(gray_image, debug_image, gray_to_rgb@CV)

    # Reset the {Tag} allocator data structures:
    tags :@= extractor.tags
    call trim@(tags, 0)

    # Iterate over all of the countours:
    big :@= map.big
    contours_count :@= 0
    contour :@= contours
    while contour !== null@CV_Sequence
	# Keep a count of total countours:
	contours_count := contours_count + 1
	#call d@(form@("contours_count=%d%\n\") / f@(contours_count))

	# Perform a polygon approximation of {contour}:
	arc_length :@=
	  integer@(arc_length@CV(contour, whole_seq@CV, 1i) * 0.02)
	poly_contour :@= approx_poly@CV(contour,
	  128i, storage, poly_approx_dp@CV, arc_length, 0.0)
	if debug_index = 5
	    green :@= extractor.green
	    call draw_contours@CV(debug_image,
	      poly_contour, green, green, 2i, 2i, 1i, origin)

	# Compute the area of the contour:
	area :@=
	  integer@(absolute@(contour_area@CV(poly_contour, whole_seq@CV, 0i)))

	# If we have a 4-sided polygon with an area greater than 500 square
	# pixels, we can explore to see if we have a tag:
	if poly_contour.total = 4i &&
	  check_contour_convexity@CV(poly_contour) && area > 500i
	    # For debugging, display the polygons in red:
	    #call d@("Have 4 sides > 500i\n\")

	    if debug_index = 6
		red :@= extractor.red
		call draw_contours@CV(debug_image,
		  poly_contour, red, red, 2i, 2i, 1i, origin)
		
	    # Copy the 4 corners from {poly_contour} to {corners_vector}:
	    corners_vector :@= extractor.corners_vector
	    index :@= 0
	    while index < 4
		corner :@= corners_vector[index]
		point :@= point_fetch@(poly_contour, index)
		if debug_index = 6
		    call d@(form@("point[%d%] x:%d% y:%d%\n\") %
		      f@(index) % f@(point.x) / f@(point.y))
		call point_set@(corner, point)
		index := index + 1
	    
	    # Now find the sub pixel corners of {corners_vector}:
	    call find_corner_sub_pix@CV(gray_image, corners_vector, 4i,
	      extractor.size_5x5, extractor.size_m1xm1,
	      extractor.term_criteria)

	    # Ensure that the corners are in a counter_clockwise direction:
	    call corners_normalize@(corners_vector)

	    # Compute the 8 reference points for deciding whether the
	    # polygon is "tag like" in its borders:
	    references :@= references_compute@(extractor, corners_vector)

	    # For debugging show the 4 corners of the possible tag where
	    # corner0=red, corner1=green, corner2=blue, corner3=purple:
	    if debug_index = 7
		red :@= extractor.red
		index := 0
		while index < 4
		    point :@= point_fetch@(poly_contour, index)
		    x :@= point.x
		    y :@= point.y
		    color :@= red
		    text :@= ""
		    switch index
		      case 0
			color := red
			text := "red"
		      case 1
			color := extractor.green
			text := "green"
		      case 2
			color := extractor.blue
			text := "blue"
		      case 3
			color := extractor.purple
			text := "purple"
		    call cross_draw@(debug_image, x, y, color)
		    #call d@(form@("poly_point[%d%]=(%d%:%d%) %s%\n\") %
		    #  f@(index) % f@(x) % f@(y) / f@(text))
		    index := index + 1

	    # Now sample the periphery of the tag and looking for the
	    # darkest white value (i.e. minimum) and the lightest black
	    # value (i.e. maximum):
	    white_darkest :@=
	      points_minimum@Extractor(gray_image, references, 0, 3)
	    black_lightest :@=
	      points_maximum@Extractor(gray_image, references, 4, 7)

	    # {threshold} should be smack between the two:
	    threshold :@= (white_darkest + black_lightest) / 2i
	    
	    # For debugging, show the 8 points that are sampled around the
	    # the tag periphery to even decide whether to do further testing.
	    # Show "black" as green crosses, and "white" as green crosses:
	    if debug_index = 8
		red :@= extractor.red
		green :@= extractor.green
		index := 0
		while index < 8
		    reference :@= references[index]
		    x :@= round@CV(reference.x)
		    y :@= round@CV(reference.y)
		    value :@= point_sample@Extractor(gray_image, reference)
		    color :@= red
		    if value < threshold
			color := green
		    call cross_draw@(debug_image, x, y, color)
		    call d@(form@("ref[%d%:%d%]:%d%\n\") %
		      f@(x) % f@(y) / f@(value))
		    index := index + 1

	    # If we have enough contrast keep on trying for a tag match:
	    if black_lightest < white_darkest
	    	# We have a tag to try:

		# Now it is time to read all the bits of the tag out:
		sample_points :@= extractor.sample_points
		tag_bits :@= extractor.tag_bits
		bit_field :@= extractor.bit_field
		mappings :@= extractor.mappings
		tag_bytes :@= extractor.tag_bytes

		# Now compute the locations to sample for tag bits:
		call sample_points_compute@Extractor(corners_vector,
		  sample_points)

		# Extract all 64 tag bit values:
		call trim@(tag_bits, 0)
		index := 0
		while index < 64
		    # Grab the pixel value and convert into a {bit}:
		    sample_point :@= sample_points[index]
		    value :@= point_sample@Extractor(gray_image, sample_point)
		    bit :@= value < threshold
		    call append@(tag_bits, bit)

		    # For debugging 
		    if debug_index = 9
			red :@= extractor.red
			green :@= extractor.green
			cyan :@= extractor.cyan
			blue :@= extractor.blue

			# Show white bits as {red} and black bits as {green}:
			color :@= red
			if bit
			    color := green

			# Show where bit 0 and 7 are:
			if index = 0
			    # Bit 0 is {cyan}:
			    color := cyan
			if index = 7
			    # Bit 7 is {blue}:
			    color := blue

			# Now splat a cross of {color} at ({x},{y}):
			x :@= round@CV(sample_point.x)
			y :@= round@CV(sample_point.y)
			call cross_draw@(debug_image, x, y, color)

		    index := index + 1

		# Now we iterate through the 4 different mapping
		# orientations to see if any one of the 4 mappings match:
		mappings_size :@= mappings.size
		direction_index :@= 0
		while direction_index < mappings_size
		    # Grab the mapping:
		    mapping :@= mappings[direction_index]
		    if debug_index = 10
			call d@(form@("direction=%d%\n\") /
			  f@(direction_index))

		    # Contsturct the values as a sequence of 8 bytes:
		    call bits_set@(bit_field, tag_bits, mapping)
		    call trim@(tag_bytes, 0)
		    i :@= 0
		    while i < 8
			byte :@= byte_get@(bit_field, i)
			call append@(tag_bytes, byte)
			#call d@(form@("tag_byte[%d%, %d%]:%x%\n\") %
			#  f@(direction_index) % f@(i) / f@(byte))
			i := i + 1
		    #call d@("\n\")

		    # Now we need to do some FEC (Forward Error Correction):
		    fec :@= extractor.fec
		    if correct@(fec, tag_bytes)
			# We passed FEC:
			if debug_index = 10
			    call d@("fec correct\n\")

			# Now see if the two CRC's match:
			computed_crc :@= crc@(extractor, tag_bytes, 2)
			tag_crc :@= (tag_bytes[3] << 8) | tag_bytes[2]
			if computed_crc = tag_crc
			    # Yippee!!! We have a tag:
			    if debug_index = 10
				call d@("crc correct\n\")

			    # Compute {tag_id} from the the first type bytes
			    # of {tag_bytes}:
			    tag_id :@= (tag_bytes[1] << 8) | tag_bytes[0]

			    # Lookup {tag} from {tag_id}:
			    tag :@= null@Tag
			    if tag_exists@(map, tag_id)
				tag :=
				  tag_lookup@(map, tag_id,"Extract@Extractor")
			    else
				# This actually needs a little discussion.
				# The actual x, y, and angle for this tag
				# is not known until after {map_update@Map}()
				# is called at the end of this routine.
				# We set {tag.x} to {big} to remember that
				# this tag is essentially uninitialized.
				# After the call to {map_update@Map}(), we
				# quickly verify that each {Tag} in {tags}
				# has had its x, y, and angle initialized.
				tag := tag_create@(map,
				  tag_id, 0.0, 0.0, 0.0, 7.8125, "Extractor")
				tag.xx := big

			    # Load {direction_index} and {corners_vector}
			    # into {tag}:
			    call record@(tag,
			      direction_index, corners_vector, indent1)
			    call append@(tags, tag)

			    if debug_index = 10
				call d@(form@("%t%\n\") / f@(tag))
				xx :@= round@CV(tag.center_x)
				yy :@= round@CV(tag.center_y)
				cyan :@= extractor.cyan
				call cross_draw@(debug_image, xx, yy, cyan)

			    break

		    direction_index := direction_index + 1

	# Grab the next {contour}:
	contour := contour.next
    # {tags} contains all of the {Tag} objects found in the image:

    # Just for consistency sort by tag id:
    call sort@(tags, compare@Tag)

    # Perform any needed tag pairing:
    constants :@= extractor.constants
    tags_size :@= tags.size
    if tags_size >= 2
	rows :@= unsigned@(gray_image.height)
	columns :@= unsigned@(gray_image.width)

	# Iterate through all pairs, using a "triangle" scan:
	tag1_index :@= 0
	while tag1_index < tags_size - 1
	    tag1 :@= tags[tag1_index]
	    tag2_index :@= tag1_index + 1
	    while tag2_index < tags_size
		tag2 :@= tags[tag2_index]
		assert tag1.id != tag2.id
		call pair@(tag1, tag2, columns, rows, map, constants, indent1)
		call pair@(tag2, tag1, columns, rows, map, constants, indent1)
		tag2_index := tag2_index + 1
	    tag1_index := tag1_index + 1

	# Clear changed tag in all {Tag_Neighbors}:
	need_map_update :@= 0f
	tag_index :@= 0
	while tag_index < tags_size
	    tag :@= tags[tag_index]
	    neighbors :@= tag.neighbors
	    neighbors_size :@= neighbors.size
	    neighbor_index :@= 0
	    while neighbor_index < neighbors_size
		neighbor :@= neighbors[neighbor_index]
		if neighbor.changed
		    neighbor.changed := 0f
		    map.changed := map_changed + 1
		    need_map_update := 1t
		    #call d@(form@("[%d%, %d%]:%n%\n\") %
		    #  f@(tag_index) % f@(neighbor_index) / f@(neighbor))
		neighbor_index := neighbor_index + 1
	    tag_index := tag_index + 1

	if need_map_update #&& !map.locked
	    # Update {map}:
	    call map_update@(map, "Extractor", indent1)
	    #call map_update@(map, "Extractor", 0)
    else
	# We are just beginning, so run {map_update@Map}() to get the
	# first tag mapped.


    # As we scan through {tags} we want to keep track of which one
    # is closest to the image center:
    bogus_index :@= 0xffffffff
    closest_tag_distance :@= big
    closest_tag_index :@= bogus_index
    next_closest_tag_distance :@= big
    next_closest_tag_index :@= bogus_index

    # Compute the row and column for the image center:
    half_width :@= double@(extractor.width) / 2.0
    half_height :@= double@(extractor.height) / 2.0

    # Iterate through {tags}:
    mapping_names :@= extractor.mapping_names
    index :@= 0
    while index < tags_size
	# Grab the {index}'th {tag}:
	tag :@= tags[index]

	# Figure out the distance between {tag} and image center:
	tag_id :@= tag.id
	center_x :@= tag.center_x
	center_y :@= tag.center_y
	dx :@= half_width - center_x
	dy :@= half_height - center_y
	center_distance :@= square_root@(dx * dx + dy * dy)

	# Remember if this {tag} is the closest.  Sometimes {tag} is
	# brand new, but has not auto mapped to a position on the
	# map yet.  We do not treat such a tag has valid yet
	# We mark the tag as unmapped with {tag.x = big}:
	if center_distance < closest_tag_distance && tag.x < big
	    closest_tag_distance := center_distance
	    closest_tag_index := index

	# For debugging keep track of 
	if debug_index >= 10
	    # Keep track of direction:
	    direction :@= tag.direction
	    mapping_name :@= mapping_names[direction]
	    call d@(form@("Tag:%d% direction=%d% mapping=%s%\n\") %
	      f@(tag_id) % f@(direction) / f@(mapping_name))

	    # For debugging draw crosses on all 4 corners (0=>red, 1=>green,
	    # 2=>blue, 3=>purple):
	    tag_corners :@= tag.corners
	    corner_index :@= 0
	    while corner_index < 4
		tag_corner :@= tag_corners[index]
		x :@= round@CV(tag_corner.x)
		y :@= round@CV(tag_corner.y)
		color :@= extractor.red
		text :@= ""
		switch corner_index
		  case 0
		    color := extractor.red
		    text := "red"
		  case 1
		    color := extractor.green
		    text := "green"
		  case 2
		    color := extractor.blue
		    text := "blue"
		  case 3
		    color := extractor.purple
		    text := "purple"

		call cross_draw@(debug_image, x, y, color)
		call d@(form@("Tag[%d%]: corner[%d%]=(%d%:%d%) %s%\n\") %
		  f@(tag.id) % f@(corner_index) % f@(x) % f@(y) / f@(text))
		corner_index := corner_index + 1

	# Compute the robot location using the {tag}:
	call robot_location_compute@(extractor, tag, indent1)

	index := index + 1

    # If we had a closest tag, compute where image center is relative to tag:
    if closest_tag_index = bogus_index
	# Mark that we did not get anything this time:
	extractor.last_tag := null@Tag
    else
	# Grab the closest {tag}:
	tag :@= tags[closest_tag_index]

	# Load up {extractor}:
	dx :@= tag.camera_x - tag.x
	dy :@= tag.camera_y - tag.y
	camera_center_distance :@= square_root@(dx * dx + dy * dy)

	# Step 1: Remember the previous values of {extractor}:
	extractor.previous_x := extractor.last_x
	extractor.previous_y := extractor.last_y
	extractor.previous_bearing := extractor.last_bearing

	# Step 2: Stuff new values into {extractor}:
	extractor.last_bearing := tag.robot_bearing
	extractor.last_distance := camera_center_distance
	extractor.last_tag := tag
	extractor.last_x := tag.robot_x
	extractor.last_y := tag.robot_y

    #call d@(form@("Coutours count=%d%\n\") / f@(contours_count))
    #call d@("Extractor 4\n\")

    if debug_index >= 10
	size :@= tags.size
	index := 0
	while index < size
	    tag :@= tags[index]
	    call show@(tag)
	    index := index + 1

    if trace
	call d@(form@("%p%<=extract@Extractor(*, *, %d%) => [") %
	  f@(indent) / f@(debug_index))
	size :@= tags.size
	index := 0
	while index < size
	    tag :@= tags[index]
	    call d@(form@(" %d%") / f@(tag.id))
	    index := index + 1
	call d@("]\n,n\")

    return tags


#	# A tag that has not been mapped has {tag.x = big}.  We can not
#	# use an unmapped tag:
#	assert tag.x < big
#
#	# For debugging, show the center of the image:
#	if debug_index >= 10
#	    call cross_draw@(debug_image,
#	      integer@(half_width), integer@(half_height), extractor.cyan)
#
#	# Compute tag center to image center distance in pixels (OpenCV coords):
#	tag_center_x :@= tag.center_x
#	tag_center_y :@= tag.center_y
#	dx :@= half_width - tag_center_x
#	dy :@= half_height - tag_center_y
#	center_distance_pixels :@= square_root@(dx * dx + dy * dy)
#
#	# Compute the number of pixels across {tag} diagonally:
#	tag_diagonal_pixels :@= diagonal@(tag)
#
#	# Tags are 7.75 inches square and hence {sqrt2} * 7.75 across.
#	# Compute how wide the pixels are:
#	sqrt2 :@= square_root@(2.0)
#	inches_per_pixel :@=  7.50 * sqrt2 / tag_diagonal_pixels
#
#	# Convert from pixels to inches:
#	center_distance_inches :@= center_distance_pixels * inches_per_pixel
#
#	# Compute bearing to tag center in radians from center of image.
#	# We invert {dy} to switch from the image coordinate system
#	# (OpenCV coords, Y axis going down) to cartesian coordinate
#	# system (Y axis going up.):
#	center_bearing :@= arc_tangent2@(-dy, dx)
#
#	# The X axis on the ceiling is in one direction.  The corresponding
#	# X axis on the floor is in the opposite direction.  Hence, we
#	# adjust the angle by 180 degress (i.e. {pi} radians):
#	pi :@= extractor.pi
#	twist :@= tag.twist
#	bearing :@= angle_normalize@(twist - pi)
#
#	angle :@= angle_normalize@(bearing - center_bearing)
#	
#	constants :@= extractor.constants
#	r2d :@= 180.0 / pi
#	#call d@(form@(
#	#  "T%d%: ta=%2f% tw=%2f% ca=%2f% a=%2f% b=%2f%\n\") %
#	#  f@(tag.id) % f@(tag.angle * r2d) % f@(tag.twist * r2d) %
#	#  f@(center_bearing * r2d) % f@(angle * r2d) / f@(bearing * r2d))
#
#	# The location of {tag} in floor coordinates is ({tag.x}, {tag.y}).
#	# The distance from tag center to the camera center is
#	# {center_distance_inches}.  {angle} is angle from the tag center
#	# to the camera center in floor coordinate system.  Now we can
#	# compute the absolute location of the camera in floor coordnates:
#	camera_x :@= tag.x + center_distance_inches * cosine@(angle)
#	camera_y :@= tag.y + center_distance_inches * sine@(angle)
#
#	# Now compute the robot center in relation to the camera center:
#
#	# Step 1: Grab the camera offset from robot center with the robot
#	# pointing due east:
#	camera_dx :@= constants.camera_dx
#	camera_dy :@= constants.camera_dy
#
#	# Step 2: Compute the distance from the camera center to the
#	# robot center:
#	camera_distance :@=
#	  square_root@(camera_dx * camera_dx + camera_dy * camera_dy)
#	robot_distance :@= camera_distance
#
#	# Step 3: Compute the angle from the robot center to the camera center
#	# (with the robot pointing due east):
#	camera_angle :@= arc_tangent2@(camera_dy, camera_dx)
#	robot_trace :@= 0f
#	#robot_trace := 1t
#	if robot_trace
#	    call d@(form@("cdx=%2f% cdy=%2f% cd=%2f% ca=%2f%\n\") %
#	      f@(camera_dx) % f@(camera_dy) % f@(camera_distance) /
#	      f@(camera_angle * 180.0 / pi))
#
#	# Step 4: The angle from the camera center to the robot center
#	# (with the robot pointing due east) differs by 180 degrees from
#	# {camera_angle}:
#	robot_angle :@= camera_angle + pi
#
#	# Step 5: The {robot_twist} is the sum of the robot bearing (floor
#	# coordinates) and the angle from the camera to the robot center
#	# ({robot_angle}).  This provides then absolute angle of rotation
#	# in floor coordinates to get to the robot center from camera center:
#	robot_twist :@= bearing + robot_angle
#
#	# Step 6: Make {robot_twist} be between -{pi} and {pi}:
#	if robot_twist > pi
#	    robot_twist := robot_twist - pi * 2.0
#	else_if robot_angle < -pi
#	    robot_twist := robot_twist + pi * 2.0
#
#	# Step 7: Now we can compute the robot center ({robot_x}, {robot_y})
#	# as an offset from the the camera center ({camera_x}, {camera_y})
#	# using polar coordinates of {robot_twist} and {robot_distance}:
#	robot_x :@= camera_x + robot_distance * cosine@(robot_twist)
#	robot_y :@= camera_y + robot_distance * sine@(robot_twist)
#	if robot_trace
#	    call d@(form@("ra=%2f% rtw=%2f% rx=%2f% ry=%2f%\n\") %
#	      f@(robot_angle * 180.0 / pi) % f@(robot_twist * 180.0 / pi) %
#	      f@(robot_x) / f@(robot_y))


routine mapping_check@Extractor
    takes extractor Extractor
    takes mapping Array[Unsigned]
    takes label String
    returns_nothing

    # This routine will verifty that {mapping} is complete using {extractor}
    # to get a temporary mapping.  "label" is used for the error message.

    temporary_mapping :@= extractor.mapping
    call trim@(temporary_mapping, 0)
    call array_append@(temporary_mapping, mapping)
    call sort@(temporary_mapping, compare@Unsigned)
    index :@= 0
    while index < 64
	temp :@= temporary_mapping[index]
	#call d@(form@("[%s%, %d%]: sort:%d%\n\") %
	#  f@(label) % f@(index) / f@(temp))
	if temp != index
	    call d@(form@("%v% mapping has an error at %d%\n\") %
	      f@(label) / f@(index))
	    #assert 0f
	index := index + 1


routine point_sample@Extractor
    takes image CV_Image
    takes point CV_Point2D32F
    returns Integer

    # This routine will return a sample ...

    x :@= round@CV(point.x)
    y :@= round@CV(point.y)
    center :@= gray_fetch@(image, x, y)
    left :@= gray_fetch@(image, x - 1i, y)
    right :@= gray_fetch@(image, x + 1i, y)
    lower :@= gray_fetch@(image, x, y - 1i)
    upper :@= gray_fetch@(image, x, y + 1i)
    result :@= -1i
    if center >= 0i && left >= 0i && right >= 0i && lower >= 0i && upper >= 0i
	result := (center + left + right + lower + upper) / 5i
    return result


routine points_maximum@Extractor
    takes image CV_Image
    takes points Array[CV_Point2D32F]
    takes start_index Unsigned
    takes end_index Unsigned
    returns Integer

    # This routine will sweep from {start_index} to {end_index} through
    # {points}.  Using each selected point in {points}, the corresponding
    # value in {image} is sampled.  The minimum of the sampled point is
    # returned.

    # Make sure that there will be no bounds error:
    assert end_index <= points.size

    # Start with a big value move it down:
    result :@= 0i

    # Iterate across the {points} from {start_index} to {end_index}:
    index :@= start_index
    while index <= end_index
	point :@= points[index]
	value :@= point_sample@Extractor(image, point)
	#call d@(form@("max[%f%:%f%]:%d%\n\") %
	#  f@(point.x) % f@(point.y) / f@(value))
	if value > result
	    # New maximum value:
	    result := value
	index := index + 1
    return result


routine points_minimum@Extractor
    takes image CV_Image
    takes points Array[CV_Point2D32F]
    takes start_index Unsigned
    takes end_index Unsigned
    returns Integer

    # This routine will sweep from {start_index} to {end_index} through
    # {points}.  Using each selected point in {points}, the corresponding
    # value in {image} is sampled.  The minimum of the sampled point is
    # returned.

    # Make sure that there will be no bounds error:
    assert end_index <= points.size

    # Start with a big value move it down:
    result :@= integer@(0x7fffffff)

    # Iterate across the {points} from {start_index} to {end_index}:
    index :@= start_index
    while index <= end_index
	point :@= points[index]
	value :@= point_sample@Extractor(image, point)
	if value < result
	    # New minimum value:
	    result := value
	index := index + 1
    return result


routine references_compute@Extractor
    takes extractor Extractor
    takes corners CV_Point2D32F_Vector
    returns Array[CV_Point2D32F]

    # This routine will use the 4 corner points in {corners} to
    # compute 8 reference points that returned.  The first 4 reference
    # points will be just outside of the quadrateral formed by {corners}
    # (i.e. the white bounding box) and the last 4 reference points are
    # on the inside (i.e. the black bounding box).

    # Extract the 8 references from {references}:
    references :@= extractor.references
    assert references.size = 8
    reference0 :@= references[0]
    reference1 :@= references[1]
    reference2 :@= references[2]
    reference3 :@= references[3]
    reference4 :@= references[4]
    reference5 :@= references[5]
    reference6 :@= references[6]
    reference7 :@= references[7]

    # Extract the 4 corners from {corners}:
    corner0 :@= corners[0]
    corner1 :@= corners[1]
    corner2 :@= corners[2]
    corner3 :@= corners[3]

    # Extract the x and y references from {corner0} through {corner3}:
    x0 :@= corner0.x
    y0 :@= corner0.y
    x1 :@= corner1.x
    y1 :@= corner1.y
    x2 :@= corner2.x
    y2 :@= corner2.y
    x3 :@= corner3.x
    y3 :@= corner3.y

    dx21 :@= x2 - x1
    dy21 :@= y2 - y1
    dx30 :@= x3 - x0
    dy30 :@= y3 - y0

    # Determine the points ({xx0, yy0}) and ({xx1, yy1}) that determine
    # a line parrallel to one side of the quadralatal:
    xx0 :@= x1 + dx21 * 5.0 / 20.0
    yy0 :@= y1 + dy21 * 5.0 / 20.0
    xx1 :@= x0 + dx30 * 5.0 / 20.0
    yy1 :@= y0 + dy30 * 5.0 / 20.0

    # Set the outside and inside reference points along the line
    # through points ({xx0, yy0}) and ({xx1, yy1}):
    dxx10 :@= xx1 - xx0
    dyy10 :@= yy1 - yy0
    call x_set@(reference0, xx0 + dxx10 * -1.0 / 20.0)
    call y_set@(reference0, yy0 + dyy10 * -1.0 / 20.0)
    call x_set@(reference4, xx0 + dxx10 * 1.0 / 20.0)
    call y_set@(reference4, yy0 + dyy10 * 1.0 / 20.0)
    call x_set@(reference1, xx0 + dxx10 * 21.0 / 20.0)
    call y_set@(reference1, yy0 + dyy10 * 21.0 / 20.0)
    call x_set@(reference5, xx0 + dxx10 * 19.0 / 20.0)
    call y_set@(reference5, yy0 + dyy10 * 19.0 / 20.0)

    # Determine the points ({xx2, yy2}) and ({xx3, yy3}) that determine
    # a line parrallel to the other side of the quadralatal:
    xx2 :@= x1 + dx21 * 15.0 / 20.0
    yy2 :@= y1 + dy21 * 15.0 / 20.0
    xx3 :@= x0 + dx30 * 15.0 / 20.0
    yy3 :@= y0 + dy30 * 15.0 / 20.0

    # Set the outside and inside reference points along the line
    # through points ({xx2, yy2}) and ({xx3, yy3}):
    dxx32 :@= xx3 - xx2
    dyy32 :@= yy3 - yy2
    call x_set@(reference2, xx2 + dxx32 * -1.0 / 20.0)
    call y_set@(reference2, yy2 + dyy32 * -1.0 / 20.0)
    call x_set@(reference6, xx2 + dxx32 * 1.0 / 20.0)
    call y_set@(reference6, yy2 + dyy32 * 1.0 / 20.0)
    call x_set@(reference3, xx2 + dxx32 * 21.0 / 20.0)
    call y_set@(reference3, yy2 + dyy32 * 21.0 / 20.0)
    call x_set@(reference7, xx2 + dxx32 * 19.0 / 20.0)
    call y_set@(reference7, yy2 + dyy32 * 19.0 / 20.0)

    return references


routine sample_points_compute@Extractor
    takes corners CV_Point2D32F_Vector
    takes sample_points Array[CV_Point2D32F]
    returns_nothing

    # This routine will use the 4 corners in {corners} as a quadralateral
    # to compute an 8 by 8 grid of tag bit sample points and store the
    # results into the the 64 preallocated {CV_Point2D32F} objects in
    # {sample_points}.  The quadralateral must be convex and in the
    # counter-clockwise direction.  Bit 0 will be closest to corners[1],
    # bit 7 will be closest to corners[0], bit 56 closest to corners[2] and
    # bit 63 closest to corners[3].

    # Extract the 4 corners from {corners}:
    assert sample_points.size = 64
    corner0 :@= corners[0]
    corner1 :@= corners[1]
    corner2 :@= corners[2]
    corner3 :@= corners[3]

    # Extract the x and y references from {corner0} through {corner3}:
    x0 :@= corner0.x
    y0 :@= corner0.y
    x1 :@= corner1.x
    y1 :@= corner1.y
    x2 :@= corner2.x
    y2 :@= corner2.y
    x3 :@= corner3.x
    y3 :@= corner3.y

    # Figure out the vector directions {corner1} to {corner2}, as well as,
    # the vector from {corner3} to {corner0}.  If {corners} specify a
    # quadralateral, these vectors should be approximately parallel:
    dx21 :@= x2 - x1
    dy21 :@= y2 - y1
    dx30 :@= x3 - x0
    dy30 :@= y3 - y0

    # {index} will cycle through the 64 sample points in {sample_points}:
    index :@= 0

    # There are ten rows (or columns) enclosed by the quadralateral.
    # (The outermost "white" rows and columns are not enclosed by the
    # quadralateral.)  Since we want to sample the middle 8 rows (or
    # columns), We want a fraction that goes from 3/20, 5/20, ..., 17/20.
    # The fractions 1/20 and 19/20 would correspond to a black border,
    # which we do not care about:
    i_fraction :@= 3.0 / 20.0
    i_increment :@= 2.0 / 20.0

    # Loop over the first axis of the grid:
    i :@= 0
    while i < 8

	# Compute ({xx1},{yy1}) which is a point that is {i_fraction} between
	# ({x1},{y1}) and ({x2},{y2}), as well as, ({xx2},{yy2}) which is a
	# point that is {i_fraction} between ({x0},{y0}) and ({x3},{y3}).
        xx1 :@= x1 + dx21 * i_fraction
        yy1 :@= y1 + dy21 * i_fraction
        xx2 :@= x0 + dx30 * i_fraction
        yy2 :@= y0 + dy30 * i_fraction

	# Compute the vector from ({xx1},{yy1}) to ({xx2},{yy2}):
	dxx21 :@= xx2 - xx1
	dyy21 :@= yy2 - yy1

	# As with {i_fraction}, {j_fraction} needs to sample the
	# the data stripes through the quadralateral with values
	# that range from 3/20 through 17/20:
	j_fraction :@= 3.0 / 20.0
	j_increment :@= 2.0 / 20.0

        # Loop over the second axis of the grid:
	j :@= 0
	while j < 8
	    # Fetch next {sample_point}:
	    sample_point :@= sample_points[index]
	    index := index + 1

            # Write the rvGrid position into the rvGrid array:
            call x_set@(sample_point, xx1 + dxx21 * j_fraction)
            call y_set@(sample_point, yy1 + dyy21 * j_fraction)

	    # Increment {j_faction} to the sample point:
	    j_fraction := j_fraction + j_increment
	    j := j + 1

	# Increment {i_fraction} to the next sample striple:
	i_fraction := i_fraction + i_increment
	i := i + 1

    sample_point0 :@= sample_points[0]
    sample_point7 :@= sample_points[7]
    sample_point56 :@= sample_points[56]
    sample_point63 :@= sample_points[63]

    # clockwise direction.  Bit 0 will be closest to corners[1], bit 7
    # will be closest to corners[0], bit 56 closest to corners[2] and
    # bit 63 closest to corners[3].

    #call sample_points_helper@Extractor("0:7", corner0, sample_point7)
    #call sample_points_helper@Extractor("1:0", corner1, sample_point0)
    #call sample_points_helper@Extractor("2:56", corner2, sample_point56)
    #call sample_points_helper@Extractor("3:63", corner3, sample_point63)


routine sample_points_helper@Extractor
    takes label String
    takes corner CV_Point2D32F
    takes sample_point CV_Point2D32F
    returns_nothing

    call d@(form@("Label: %v% corner: %f%:%f% sample_point %f%:%f%\n\") %
      f@(label) % f@(integer@(corner.x)) % f@(integer@(corner.y)) %
      f@(integer@(sample_point.x)) / f@(integer@(sample_point.y)))


routine size_set@Extractor
    takes extractor Extractor
    takes width Integer
    takes height Integer
    returns_nothing

    # This will set {extractor} to work on an image that is
    # {width} by {height} pixels in size.

    size :@= create@CV_Size(width, height)
    extractor.debug_image := create_image@CV(size, depth_8u@CV, 3i)
    extractor.edge_image := create_image@CV(size, depth_8u@CV, 1i)
    extractor.gray_image := create_image@CV(size, depth_8u@CV, 1i)
    extractor.height := height
    extractor.size := size
    extractor.width := width
    

routine robot_location_compute@Extractor
    takes extractor Extractor
    takes tag Tag
    takes indent Unsigned
    returns_nothing

    # This routine will compute the (rx, ry, ra) using the {tag}
    # in the image associated with {extractor}.  The results are
    # stored back into tag in the {robot_bearing}, {robot_x}, and
    # {robot_y} fields.

    # This code is heavily dependent on the large block comment
    # preceding this routine definition.

    trace :@= indent < 0xffff0000
    if trace
	call d@(form@("%p%=>robot_location_compute@(T%d%)\n\") %
	  f@(indent) / f@(tag.id))
    indent1 :@= indent + 1

    # (rx, ry, rb) correspond to {robot_x}, {robot_y}, and {robot_bearing}.
    # We initialize these three values to zero, just in case {tag} has
    # not had its (x, y) position set:
    robot_x :@= 0.0
    robot_y :@= 0.0
    robot_bearing :@= 0.0

    # A tag that has not been mapped has {tag.x = big}.  We can not
    # use an unmapped tag:
    map :@= extractor.map
    big :@= map.big
    if tag.x < big
	# The tag is represented by (tid, tx, ty, tb, te) which correspond
	# to {tag_id}, {tag_x}, {tag_y}, {tag_angle}, and {tag_edge_length}.
	# Extract these values from {tag}:
	tag_id :@= tag.id
	tag_x :@= tag.x
	tag_y :@= tag.y
	tag_bearing :@= tag.bearing
	tag_edge_length :@= tag.edge_length

	# We are going to be need {pi}:
	pi :@= extractor.pi

	if trace
	    call d@(form@("%p%tid=%d% tx=%2f% ty=%2f% tb=%2f% te=%2f%\n\") %
	      f@(indent1) % f@(tag_id) % f@(tag_x) % f@(tag_y) %
	      f@(tag_bearing * 180.0 / pi) / f@(tag_edge_length))

	# Show the corners for {trace}'ing:
	if trace
	    corners :@= tag.corners
	    c0 :@= corners[0]
	    c1 :@= corners[1]
	    c2 :@= corners[2]
	    c3 :@= corners[3]
	    call d@(form@(
	     "%p%c0=%2f%:%2f% c1=%2f%:%2f% c2=%2f%:%2f% c3=%2f%:%2f%\n\") %
	     f@(indent1) %
	     f@(c0.x) % f@(c0.y) % f@(c1.x) % f@(c1.y) %
	     f@(c2.x) % f@(c2.y) % f@(c3.x) / f@(c3.y))

	# Both {tag_center_x}, {tag_center_y}, and {tag_twist} are already
	# computed in {tag} by {record@Tag}():
	tag_center_x :@= tag.center_x
	tag_center_y :@= tag.center_y
	tag_diagonal :@= tag.diagonal

	# {tag_twist} is the bottom edge angle relative to image X axis:
	tag_twist :@= tag.twist

	if trace
	    call d@(
	      form@("%p%tgctrx=%6f% tgctry=%6f% tgdiag=%2f% tgtwist=%2f%\n\") %
	      f@(indent1) %
	      f@(tag_center_x) % f@(tag_center_y) % f@(tag_diagonal) /
	      f@(tag_twist * 180.0 / pi))

	# (camctrx, camctry) correspond to {camera_center_x} and
	# {camera_center_y}:
	image_width :@= double@(extractor.width)
	image_height :@= double@(extractor.height)
	camera_center_x :@= image_width / 2.0
	camera_center_y :@= image_height / 2.0

	# Now we can compute {camdist} and {camctrangle}, which correspond to
	# {camera_distance} and {camera_angle}:
	camera_distance_dx :@= camera_center_x - tag_center_x
	camera_distance_dy :@= camera_center_y - tag_center_y

	if trace
	    #call d@(form@("%p%camctrx=%2f% camctry=%2f%\n\") %
	    #  f@(camera_center_x) / f@(camera_center_y))
	    call d@(form@("%p%cam_dist_dx=%2f% cam_dist_dy=%2f%\n\") %
	      f@(indent1) % f@(camera_distance_dx) / f@(camera_distance_dy))

	camera_distance :@= square_root@(
	  camera_distance_dx * camera_distance_dx +
	  camera_distance_dy * camera_distance_dy)
	camera_center_angle :@=
	  arc_tangent2@(camera_distance_dy, camera_distance_dx)

	# flrcamdist corresponds to {floor_distance}:
	constants :@= extractor.constants
	inches_per_pixel :@= constants.inches_across_frame / image_width
	floor_camera_distance :@= camera_distance * inches_per_pixel

	if trace
	    call d@(form@(
	      "%p%camctrangle=%2f% camdist=%2f% flrcamdist=%2f%\n\") %
	      f@(indent1) % f@(camera_center_angle * 180.0 / pi) %
	      f@(camera_distance) / f@(floor_camera_distance))

	# cb corresponds to {camera_bearing}:
	camera_bearing :@= angle_normalize@(tag_bearing - tag_twist)

	# ca corresponds to {camera_angle}:
	camera_angle :@= angle_normalize@(camera_bearing + camera_center_angle)

	# (cx, cy) corresponds to ({camera_x}, {camera_y}):
	camera_x :@= tag_x + floor_camera_distance * cosine@(camera_angle)
	camera_y :@= tag_y + floor_camera_distance * sine@(camera_angle)

	# Load (cx, cy, cb) into {tag}:
	tag.camera_x := camera_x
	tag.camera_y := camera_y
	tag.camera_bearing := camera_bearing

	if trace
	    call d@(form@("%p%cx=%2f% cy=%2f% cb=%2f% ca=%2f%\n\") %
	      f@(indent1) % f@(camera_x) % f@(camera_y) %
	      f@(camera_bearing * 180.0 / pi) /
	      f@(camera_angle * 180.0 / pi))
	    
	# Compute the final robot position
	robot_camera_dx :@= constants.camera_dx
	robot_camera_dy :@= constants.camera_dy
	robot_camera_twist :@= constants.camera_twist
	robot_distance :@= square_root@(
	  robot_camera_dx * robot_camera_dx +
	  robot_camera_dy * robot_camera_dy)

	# (rx, ry, rb) corresponds to ({robot_x}, {robot_y}, {robot_bearing}):
	robot_bearing := angle_normalize@(camera_bearing + robot_camera_twist)

	#FIXME: Use arc_tangent2@(robot_camera_dy, robot_camera_dy):!!!

	# Do the final robot location computation:
	robot_x := camera_x + robot_distance * cosine@(robot_bearing)
	robot_y := camera_y + robot_distance * sine@(robot_bearing)

	if trace
	    call d@(form@("%p%rx=%2f% ry=%2f% rb=%2f%\n\") % f@(indent1) %
	      f@(robot_x) % f@(robot_y) / f@(robot_bearing * 180.0 / pi))

    # Store the (rx, ry, rb) results back into {tag}:
    tag.robot_bearing := robot_bearing
    tag.robot_x := robot_x
    tag.robot_y := robot_y

    if trace
	call d@(form@("%p%<=robot_location_compute@(T%d%)\n\") %
	  f@(indent) / f@(tag.id))


# {CV_Matrix} routines:

routine is_clockwise@CV_Matrix
    takes matrix CV_Matrix
    returns Logical

    # Extract X and Y for all four corners:
    x0 :@= get_real_2d@CV(matrix, 0i, 0i)
    y0 :@= get_real_2d@CV(matrix, 0i, 1i)
    x1 :@= get_real_2d@CV(matrix, 1i, 0i)
    y1 :@= get_real_2d@CV(matrix, 1i, 1i)
    x2 :@= get_real_2d@CV(matrix, 2i, 0i)
    y2 :@= get_real_2d@CV(matrix, 2i, 1i)

    # Create two vectors from the first two lines of the polygon:
    v1x :@= x1 - x0
    v1y :@= y1 - y0
    v2x :@= x2 - x1
    v2y :@= y2 - y1

    # Determine the sign of the Z coordinate of the cross product:
    z :@= v1x * v2y - v2x * v1y

    # If the Z coordinate is negative, to reverse the sequence of the corners:
    return z < 0.0


routine show@CV_Matrix
    takes matrix CV_Matrix
    takes label String
    takes out_stream Out_Stream

    # This routine will print {matrix} to {out_stream} labeled with {label}.

    rows :@= matrix.rows
    columns :@= matrix.columns
    call put@(form@("[%s% %d% x %d%]\n") %
      f@(label) % f@(rows) / f@(columns), out_stream)
    i :@= 0i
    while i < rows
	j :@= 0i
	while j < columns
	    call put@(form@(" %f%") /
	      f@(get_real_2d@CV(matrix, i, j)), out_stream)
	    j := j + 1i
	call put@("\n\", out_stream)
	i := i + 1i
    call put@("\n\", out_stream)
    call flush@(out_stream)


# {CV_Point2D32F} routines:

routine contents_copy@CV_Point2D32F
    takes to_point CV_Point2D32F
    takes from_point CV_Point2D32F
    returns_nothing

    # This routine will copy the contents of {from_point} into {to_point}.

    call x_set@(to_point, from_point.x)
    call y_set@(to_point, from_point.y)


routine is_clockwise@CV_Point2D32F_Vector
    takes corners CV_Point2D32F_Vector
    returns Logical

    # Extract the four corners:
    corner0 :@= corners[0]
    corner1 :@= corners[1]
    corner2 :@= corners[2]

    # Extract X and Y for all four corners:
    x0 :@= corner0.x
    y0 :@= corner0.y
    x1 :@= corner1.x
    y1 :@= corner1.y
    x2 :@= corner2.x
    y2 :@= corner2.y

    # Create two vectors from the first two lines of the polygon:
    v1x :@= x1 - x0
    v1y :@= y1 - y0
    v2x :@= x2 - x1
    v2y :@= y2 - y1

    # Determine the sign of the Z coordinate of the cross product:
    z :@= v1x * v2y - v2x * v1y

    # If the Z coordinate is negative, to reverse the sequence of the corners:
    return z < 0.0


# {CV_Point2D32F_Vector} routines:

routine rotate@CV_Point2D32F_Vector
    takes corners CV_Point2D32F_Vector
    takes size Unsigned
    returns_nothing

    # This routine will rotate the {size} elements in {corners} by
    # one element {corners[0]=>corners[1], ... corners[size-1]=>corners[0]}.

    last_corner :@= corners[size - 1]
    previous_x :@= last_corner.x
    previous_y :@= last_corner.y

    index :@= 0
    while index < size
	corner :@= corners[index]
	x :@= corner.x
	y :@= corner.y
	call x_set@(corner, previous_x)
	call y_set@(corner, previous_y)
	previous_x := x
	previous_y := y
	index := index + 1


routine corners_normalize@CV_Point2D32F_Vector
    takes corners CV_Point2D32F_Vector
    returns_nothing

    # This routine will ensure that {corners} are ordered
    # in the counter-clockwise direction.

    if is_clockwise@(corners)
	# Extract two corners to be swapped:
	corner1 :@= corners[1]
	corner3 :@= corners[3]

	# Extract X and Y for both corners:
	x1 :@= corner1.x
	y1 :@= corner1.y
	x3 :@= corner3.x
	y3 :@= corner3.y

	# Swap contents of {corner1} and {corner3}:
	call x_set@(corner1, x3)
	call y_set@(corner1, y3)
	call x_set@(corner3, x1)
	call y_set@(corner1, x1)
	

# {Array} routines:

routine append8@Array[Element]
    takes array Array[Element]
    takes element1 Element
    takes element2 Element
    takes element3 Element
    takes element4 Element
    takes element5 Element
    takes element6 Element
    takes element7 Element
    takes element8 Element

    # This routine will append {element1} through {element8} to {array}.

    call append@(array, element1)
    call append@(array, element2)
    call append@(array, element3)
    call append@(array, element4)
    call append@(array, element5)
    call append@(array, element6)
    call append@(array, element7)
    call append@(array, element8)


# {Bit_Field} routines:

routine create@Bit_Field
    takes size Unsigned
    returns Bit_Field

    # This routine will return a {String} for use holding a bit field.
    # Up to {size} bits can be stored.

    # Create {bit_field}:
    bits :@= new@String()
    bit_field :@= new@Bit_Field()
    bit_field.size := size
    bit_field.bits := bits

    # Pad {bits} with enough 0's:
    while bits.size * 8 < size
	call character_append@(bits, '\0\')

    return bit_field


routine store1@Bit_Field
    takes bit_field Bit_Field
    takes index Unsigned
    takes value Logical
    returns_nothing

    # This routine will set the {index}'th bit of {bit_field} to {value}.

    assert index < bit_field.size
    bits_index :@= index >> 3
    bits_position :@= index & 7
    mask :@= 1 << bits_position
    bits :@= bit_field.bits
    byte :@= unsigned@(bits[bits_index])
    if value
	byte := byte | mask
    else
	byte := byte & ~mask
    bits[bits_index] := character@(byte)


routine fetch1@Bit_Field
    takes bit_field Bit_Field
    takes index Unsigned
    returns Logical

    # This routine will return the {index}'th bit of {bit_field}.

    assert index < bit_field.size
    return (unsigned@(bit_field.bits[index >> 3]) & (1 << (index & 7))) != 0


routine bits_set@Bit_Field
    takes bit_field Bit_Field
    takes tag_bits Array[Logical]
    takes mapping Array[Unsigned]
    returns_nothing

    # This routine will set the bits in {bit_field} to {tag_bits} using
    # {mapping} to control where the bits are set.

    bit_field_size :@= bit_field.size
    assert mapping.size = bit_field_size
    assert tag_bits.size = bit_field_size
    index :@= 0
    while index < bit_field_size
	bit_field[mapping[index]] := tag_bits[index]
	index := index + 1


routine bits_get@Bit_Field
    takes bit_field Bit_Field
    takes tag_bits Array[Logical]
    takes mapping Array[Unsigned]
    returns_nothing

    # This routine will get the bits from {bit_field} and store them
    # into {tag_bits} using {mapping}.

    bit_field_size :@= bit_field.size
    assert mapping.size = bit_field_size
    assert tag_bits.size = bit_field_size
    index :@= 0
    while index < bit_field_size
	tag_bits[index] := bit_field[mapping[index]]
	index := index + 1


routine byte_get@Bit_Field
    takes bit_field Bit_Field
    takes index Unsigned
    returns Unsigned

    # This routine will return the {index}'th byte of {bit_field}.

    return unsigned@(bit_field.bits[index])


routine crc@Extractor
    takes extractor Extractor
    takes buffer Array[Unsigned]
    takes count Unsigned
    returns Unsigned

    # This routine will return the CRC of the {count} bytes in {buffer}
    # using {extractor} to get the CRC lookup table

    ccitt :@= extractor.ccitt
    crc :@= 0xffff
    index :@= 0
    while index < count
	byte :@= buffer[index] & 0xff
	crc := (crc >> 8) ^ ccitt[(crc ^ byte) & 0xff]
	index := index + 1
    return crc


routine vectors_to_opengl_matrix@CV_Matrix
    takes rotation_matrix CV_Matrix
    takes rotation_vector CV_Matrix
    takes translation_vector CV_Matrix
    takes transform_matrix CV_Matrix
    returns_nothing

    # This routine converts the {translation_vector} and {rotation_vector}
    # (output from {find_extrinsic_camera_params2@CV}) into {opengl_matrix}.
    # Both {rotation_vector} and {translation_vector} are 1 x 3 and
    # {transform_matrix} must be 4 x 4.  {rotation_matrix} is a temporary
    # 3 x 3 matrix.

    # Zero the matrix:
    call set_zero@CV(transform_matrix)

    # Move {translation_vector} into {transform_matrix}:
    i :@= 0i
    while i < 3i
	call set_real_2d@CV(transform_matrix, i, 3i,
	  get_real_2d@CV(translation_vector, 0i, i))
	i := i + 1i

    # Convert {rotation_vector} into {rotation_matrix}.  {rotation_vector}
    # is a compact representation of the rotation matrix:
    call rodrigues2@CV(rotation_vector, rotation_matrix, null@CV_Matrix)

    # Move the rotation values from {rotation_matrix} into the {opengl_matrix}:
    i := 0i
    while i < 3i
	j :@= 0i
	while j < 3i
	    call set_real_2d@CV(transform_matrix, i, j,
	      get_real_2d@CV(rotation_matrix, i, j))
	    j := j + 1i
	i := i + 1i

    # Set the last element of the matrix.
    call set_real_2d@CV(transform_matrix, 3i, 3i, 1.0)


# This code was basically lifted from:
# http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToAngle/index.htm
# Thanks!
routine angle_axis_extract@CV_Matrix
    takes opengl_matrix CV_Matrix
    takes angle_axis CV_Matrix
    returns_nothing

    epsilon :@= 0.01
    epsilon2 :@= 0.1

    # Extract the rotation matrix:
    m00 :@= get_real_2d@CV(opengl_matrix, 0i, 0i)
    m01 :@= get_real_2d@CV(opengl_matrix, 0i, 1i)
    m02 :@= get_real_2d@CV(opengl_matrix, 0i, 2i)

    m10 :@= get_real_2d@CV(opengl_matrix, 1i, 0i)
    m11 :@= get_real_2d@CV(opengl_matrix, 1i, 1i)
    m12 :@= get_real_2d@CV(opengl_matrix, 1i, 2i)

    m20 :@= get_real_2d@CV(opengl_matrix, 2i, 0i)
    m21 :@= get_real_2d@CV(opengl_matrix, 2i, 1i)
    m22 :@= get_real_2d@CV(opengl_matrix, 2i, 2i)

    angle :@= 0.0
    x :@= 0.0
    y :@= 0.0
    z :@= 0.0

    # Check for singularity:
    if absolute@(m01 - m10) < epsilon &&
      absolute@(m02 - m20) < epsilon && absolute@(m12 - m21) < epsilon
	# Singularity found:

	# First check for identity matrix which must have +1 for all terms
	# in leading diagonal and zero in other terms:
 	if absolute@(m01 + m10) < epsilon2 &&
	   absolute@(m02 + m20) < epsilon2 &&
	   absolute@(m12 + m21) < epsilon2 && 
	   absolute@(m00 + m11 + m22 - 3.0) < epsilon2
	    # This singularity is identity matrix so angle = 0:
	    x := 0.0
	    y := 0.0
	    z := 1.0
	    angle := 0.0
	    call d@("I\n\")
	else
	    # Otherwise this singularity is angle = 180:
	    angle := 3.14159265358979323846
	    xx :@= (m00 + 1.0) / 2.0
	    yy :@= (m11 + 1.0) / 2.0
	    zz :@= (m22 + 1.0) / 2.0
	    xy :@= (m01 + m10) / 4.0
	    xz :@= (m02 + m20) / 4.0
	    yz :@= (m12 + m21) / 4.0
	    if xx > yy && xx > zz
		# {m00} is the largest diagonal term:
		if xx < epsilon
		    x := 0.0
		    y := 0.7071
		    z := 0.7071
		else
		    x := square_root@(xx)
		    y := xy / x
		    z := xz / x
		call d@("M00\n\")
	    else_if yy > zz
		# {m11} is the largest diagonal term:
		if yy < epsilon
		    x := 0.7071
		    y := 0.0
		    z := 0.7071
		else
		    y := square_root@(yy)
		    x := xy / y
		    z := yz / y
		call d@("M11\n\")
	    else
		# {m22} is the largest diagonal term so base result on this:
		if zz < epsilon
		    x := 0.7071
		    y := 0.7071
		    z := 0.0
		else
		    z := square_root@(zz)
		    x := xz / z
		    y := yz / z
		call d@("M22\n\")
    else
	# as we have reached here there are no singularities
	# so we can handle normally:

	# {s} is used to normalize:
	dm12 :@= m21 - m12
	dm02 :@= m02 - m20
	dm01 :@= m10 - m01
	s :@= square_root@(dm12 * dm12 + dm02 * dm02 + dm01 * dm01)

	# prevent divide by zero, should not happen if matrix is orthogonal
	# and should be caught by singularity test above, but I've left it
	# in just in case:
	if absolute@(s) < 0.001
	    s := 1.0

	#call d@(form@("xxx=%f%\n") / f@((m00 + m11 + m22 - 1.0) / 2.0))
	angle := arc_cosine@((m00 + m11 + m22 - 1.0) / 2.0)
	x := dm12 / s
	y := dm02 / s
	z := dm01 / s
	#call d@("N\n\")

    # Load up the final result:
    call set_real_2d@CV(angle_axis, 0i, 0i, x)
    call set_real_2d@CV(angle_axis, 0i, 1i, y)
    call set_real_2d@CV(angle_axis, 0i, 2i, z)
    call set_real_2d@CV(angle_axis, 0i, 3i, angle)


# {Tag} routines:

routine record@Tag
    takes tag Tag
    takes direction Unsigned
    takes vector CV_Point2D32F_Vector
    takes indent Unsigned
    returns_nothing

    # This routine will update the contents {Tag} to contain {direction},
    # and {vector}.  {vector} contains four points that form a convex
    # quadralateral in the counter-clockwise direction.  This routine will
    # compute the diagonal and twist values for {tag} as well.

    trace :@= indent < 0xffff0000
    if trace
	call d@(form@("%p%=>record@Tag(T%d%, *)\n\") % f@(indent) / f@(tag.id))
    indent1 :@= indent + 1

    tag.direction := direction

    # Load up the contents of {tag.corners} from {corners_vector} depending
    # upon {direction}:
    offset :@= 0
    switch direction
      case 0
	# North mapping:
	#offset := 2
	offset := 0
      case 1
	# East mapping:
	#offset := 1
	offset := 1
      case 2
	# South mapping:
	#offset := 0
	offset := 2
      case 3
	# West mapping:
	#offset := 3
	offset := 3
      default
	assert 0f

    # Compute {x_center} and {y_center} and fill in {corners}:
    tag_corners :@= tag.corners
    point_index :@= 0
    while point_index < 4
	corner_index :@= 0
	switch direction
	  case 0
	    corner_index := (3 - point_index + 2) & 3
	  case 1
	    corner_index := (3 - point_index + 1) & 3
	  case 2
	    corner_index := (3 - point_index + 0) & 3
	  case 3
	    corner_index := (3 - point_index + 3) & 3
	corner :@= vector[corner_index]
	x :@= corner.x
	y :@= corner.y
	tag_corner :@= tag_corners[point_index]
	tag_corner.x := x
	tag_corner.y := y
	point_index := point_index + 1

    # The comment below is out of date:
    ## The Y axis in is image coordinates goes from 0 at the top to
    ## a positive number as it goes towards the bottom.  This is the
    ## opposite direction from from normal cartisian coordinates where
    ## positive Y goes up.  Because my brain can't cope with angles
    ## unless they are in cartisian coordinates, I negate the Y axis
    ## for the purpose of computing the {twist} angles below.  This
    ## flips the direction of the Y axis.

    pi :@= 3.14159265358979323846

    # Compute {twist}:
    tag_corner0 :@= tag_corners[0]
    tag_corner1 :@= tag_corners[1]
    tag_corner2 :@= tag_corners[2]
    tag_corner3 :@= tag_corners[3]

    # Pull out the X and Y coordinates:
    x0 :@= tag_corner0.x
    y0 :@= tag_corner0.y
    x1 :@= tag_corner1.x
    y1 :@= tag_corner1.y
    x2 :@= tag_corner2.x
    y2 :@= tag_corner2.y
    x3 :@= tag_corner3.x
    y3 :@= tag_corner3.y

    # Compute the angle of the tag bottom edge to camera X axis:
    dx01 :@= x0 - x1
    dy01 :@= y0 - y1
    twist1 :@= arc_tangent2@(dy01, dx01)
    dx32 :@= x3 - x2
    dy32 :@= y3 - y2
    twist2 :@= arc_tangent2@(dy32, dx32)

    # We want the average angle of {twist1} and {twist2}.  We have
    # be careful about modular arithmetic issues.  Compute the angle
    # change and add in half of that to get the average angle:
    twist_change :@= angle_between@(twist1, twist2)
    twist :@= angle_normalize@(twist1 + twist_change / 2.0)
    tag.twist := twist

    # Compute the X/Y axis deltas for the two diagonals:
    dx02 :@= x0 - x2
    dy02 :@= y0 - y2
    dx13 :@= x1 - x3
    dy13 :@= y1 - y3

    # Compute the actual diagonals:
    diagonal02 :@= square_root@(dx02 * dx02 + dy02 * dy02)
    diagonal13 :@= square_root@(dx13 * dx13 + dy13 * dy13)

    # Compute the average diagonal:
    diagonal :@= (diagonal02 + diagonal13) / 2.0
    tag.diagonal := diagonal

    # Compute the center by averagine all for corners:
    center_x :@= (x0 + x1 + x2 + x3) / 4.0
    center_y :@= (y0 + y1 + y2 + y2) / 4.0
    tag.center_x := center_x
    tag.center_y := center_y

    if trace
	call d@(form@(
	  "%p%id=%d% c0=%2f%,%2f% c1=%2f%,%2f% c2=%2f%,%2f% c3=%2f%,%2f%\n\") %
	  f@(indent1) % f@(tag.id) %
	  f@(x0) % f@(y0) % f@(x1) % f@(y1) %
	  f@(x2) % f@(y2) % f@(x3) / f@(y3))
	call d@(form@("%p%dx01=%2f% dy01=%2f% dir=%d%\n\") %
	  f@(indent1) % f@(dx01) % f@(dy01) / f@(tag.direction))
	call d@(form@("%p%tw1=%2f% tw2=%2f% tw=%2f%\n\") %
	  f@(indent1) % f@(twist1 * 180.0 / pi) %
	  f@(twist2 * 180.0 / pi) /  f@(twist * 180.0 / pi))
	call d@(form@("%p%center_x==%2f% center_y=%2f%\n\") %
	  f@(indent1) % f@(center_x) / f@(center_y))

    # For debugging, display everything:
    if 0f	# 1t
	#call d@(form@("Mapping:%v% offset:%d%\n\") %
	#  f@(extractor.mapping_names[direction]) / f@(offset))
	index :@= 0i
	while index < 4i
	    corner := vector[unsigned@(index)]
	    vector_x :@= round@CV(corner.x)
	    vector_y :@= round@CV(corner.y)

	    #point_x :@= round@CV(get_real_2d@CV(points, index, 0i))
	    #npoint_y :@= round@CV(get_real_2d@CV(points, index, 1i))
	    #corner_x :@= round@CV(get_real_2d@CV(corners, index, 0i))
	    #corner_y :@= round@CV(get_real_2d@CV(corners, index, 1i))

	    #call d@(form@(
	    #  "[%d%]: corner_vect=%d%:%d% point=%d%:%d% corner=%d%:%d%\n\") %
	    #  f@(index) % f@(vector_x) % f@(vector_y) %
	    #  f@(point_x) % f@(point_y) %
	    #  f@(corner_x) / f@(corner_y))
	    index := index + 1i
	#call d@(form@("corners_vec CW:%l% points CW:%l% corners CW:%l%\n\") %
	#  f@(is_clockwise@(vector)) % f@(is_clockwise@(points)) /
	#  f@(is_clockwise@(corners)))

    if trace
	call d@(form@("%p%<=record@Tag(T%d%, *)\n\") % f@(indent) / f@(tag.id))

